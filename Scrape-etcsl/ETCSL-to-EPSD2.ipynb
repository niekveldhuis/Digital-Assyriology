{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETCSL - Oracc Harmonization\n",
    "\n",
    "This script will harmonize the output of the ETCSL TEI XML scraper (Notebook scrape-etcsl-XML) with Oracc lemmatization standards (epsd2). The output of this script is put in the `Cleaned` directory. The files in the `Cleaned` directory are compatible with files scraped from Oracc with the Scrape Oracc Notebook, using the same lemmatization standards and the same POS tags.\n",
    "\n",
    "The script needs the following files:\n",
    "\n",
    "1. Directory Input:\n",
    "  * etcsl.txt holding all the ETCSL text numbers\n",
    "  * Three vocabulary files with ETCSl - ORACC equivalencies (by Niek Veldhuis and Terri Tanaka):\n",
    "     * etcsl_epsd2_sux2.txt\n",
    "     * etcsl_epsd2_emesal2.txt\n",
    "     * etcsl_epsd2_propernouns2.txt\n",
    "2. Directory Output:\n",
    "  * a set of scraped etcsl files; extension .txt.\n",
    "\n",
    "The script assumes that the scraped etcsl files have the lemmatization format `sux:lugal[king]N`. If another format has been produced (by modifying the function `outputformat()` in the Notebook scrape-etcsl-XML) the script needs to be modified accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of names for the ETCSL - EPSD2 equivalency files. Create an empty dictionary that will hold these equivalencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_equiv_files = ['etcsl_epsd2_sux2.txt', 'etcsl_epsd2_emesal2.txt', 'etcsl_epsd2_propernouns2.txt']\n",
    "equiv_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `add_dict()` takes a line from one of the equivalencies files, splits the line in two and assigns the first half of the line to the key, the second to the value of a new item in the dictionary `equiv_dict`. The function `add_dict()` is called by the function `readfile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_dict(equivalencies):\n",
    "    for equiv in equivalencies:\n",
    "        etcsl = equiv.split(' = ')[0]\n",
    "        epsd2 = equiv.split(' = ')[1]\n",
    "        equiv_dict[etcsl] = epsd2\n",
    "    #equiv_dict = {equiv.split(' = ')[0] : equiv.split(' = ')[1] for equiv in equivalencies} ; this doesn't work\n",
    "    return equiv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `readfile()` reads the equivalencies lists and calls the function `add_dict()` to add each line to the dictionary `equiv_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readfile(file):\n",
    "    with open('Equivalencies/' + file, mode = 'r', encoding='utf8') as f:\n",
    "        equivalencies = f.read().splitlines()\n",
    "    equiv_dict = add_dict(equivalencies)\n",
    "    return equiv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell iterates over the list vocab_equiv_files and forwards each of these file names to the function `readfiles()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file in vocab_equiv_files:\n",
    "    equiv_dict = readfile(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The len() function is inserted here as a basic check to make sure all equivalencies have been entered in equiv_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4141"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(equiv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary, the directory `Cleaned` is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('Cleaned'):\n",
    "    os.mkdir('Cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file etcsl.txt in the directory `Input` is opened to retrieve a list of all ETCSL texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Input/etcsl.txt', mode = 'r') as f:\n",
    "    textlist = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main process iterates over the list of ETCSL texts, opens the corresponding item in the `Output` folder (this is output from the scrape-etcsl-XML Notebook) and uses the equiv_dict to replace ETCSL forms (in the key) with EPSD2 forms. The regular expression in the search/replace function looks for entries that are preceded by colon, space, or comma. This prevents partial entries from being replaced. Finally, the new version of the text is saved in the `Cleaned` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 394/394 [09:13<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "for textno in tqdm(textlist):\n",
    "    with open('Output/' + textno + '.txt', mode = 'r', encoding='utf8') as g:\n",
    "        text = g.read()\n",
    "        for entry in equiv_dict:\n",
    "            text = re.sub(r'(?<=[ :,])'+re.escape(entry), equiv_dict[entry], text)\n",
    "    with open('Cleaned/' + textno + '.txt', mode = 'w', encoding='utf8') as writeFile:\n",
    "        writeFile.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
